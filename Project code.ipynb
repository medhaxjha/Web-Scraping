{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logo='''██╗    ██╗███████╗██████╗     ███████╗ ██████╗██████╗  █████╗ ██████╗ ██╗███╗   ██╗ ██████╗     \n",
    "██║    ██║██╔════╝██╔══██╗    ██╔════╝██╔════╝██╔══██╗██╔══██╗██╔══██╗██║████╗  ██║██╔════╝     \n",
    "██║ █╗ ██║█████╗  ██████╔╝    ███████╗██║     ██████╔╝███████║██████╔╝██║██╔██╗ ██║██║  ███╗    \n",
    "██║███╗██║██╔══╝  ██╔══██╗    ╚════██║██║     ██╔══██╗██╔══██║██╔═══╝ ██║██║╚██╗██║██║   ██║    \n",
    "╚███╔███╔╝███████╗██████╔╝    ███████║╚██████╗██║  ██║██║  ██║██║     ██║██║ ╚████║╚██████╔╝    \n",
    " ╚══╝╚══╝ ╚══════╝╚═════╝     ╚══════╝ ╚═════╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═╝  ╚═══╝ ╚═════╝  '''\n",
    "\n",
    "print(logo)\n",
    "logo1='''  _______        _       _   _                   \n",
    " |__   __|      | |     | \\ | |                  \n",
    "    | | ___  ___| |__   |  \\| | _____      _____ \n",
    "    | |/ _ \\/ __| '_ \\  | . ` |/ _ \\ \\ /\\ / / __|\n",
    "    | |  __/ (__| | | | | |\\  |  __/\\ V  V /\\__ \\\n",
    "    |_|\\___|\\___|_| |_| |_| \\_|\\___| \\_/\\_/ |___/'''\n",
    "logo2='''   _       _       _   _                   \n",
    "      | |     | |     | \\ | |                  \n",
    "      | | ___ | |__   |  \\| | _____      _____ \n",
    "  _   | |/ _ \\| '_ \\  | . ` |/ _ \\ \\ /\\ / / __|\n",
    " | |__| | (_) | |_) | | |\\  |  __/\\ V  V /\\__ \\\n",
    "  \\____/ \\___/|_.__/  |_| \\_|\\___| \\_/\\_/ |___/'''\n",
    "\n",
    "def hackernews():\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        import pprint\n",
    "        res = requests.get('https://news.ycombinator.com/news')\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        links = soup.select('.titleline > a')\n",
    "        subtext = soup.select('.subtext')\n",
    "\n",
    "        def sort_stories_by_votes(hnlist):\n",
    "            return sorted(hnlist, key=lambda k: k['votes'], reverse=True)\n",
    "\n",
    "        def create_custom_hn(links, subtext):\n",
    "            hn = []\n",
    "            for idx, item in enumerate(links):\n",
    "                title = item.getText()\n",
    "                href = item.get('href', None)\n",
    "                vote = subtext[idx].select('.score')\n",
    "                if len(vote):\n",
    "                    points = int(vote[0].getText().replace(' points', ''))\n",
    "                    if points > 99:\n",
    "                        hn.append({'title': title, 'link': href, 'votes': points})\n",
    "            return sort_stories_by_votes(hn)\n",
    "        pprint.pprint(create_custom_hn(links, subtext))\n",
    "\n",
    "\n",
    "def jobscrape():\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup as soup\n",
    "        import pprint\n",
    "        page = requests.get(\"https://chennai.craigslist.org/search/jjj?query=software+engineer\")\n",
    "        bsobj = soup(page.content, 'lxml')\n",
    "        links = []\n",
    "        for link in bsobj.findAll('li', {'class': 'result-row'}):\n",
    "            links.append(link.a['href'])\n",
    "        pprint.pprint(links)\n",
    "        title = []\n",
    "        for link in links:\n",
    "            page = requests.get(link)\n",
    "            bsobj = soup(page.content, 'lxml')\n",
    "            # print(bsobj)\n",
    "            print(bsobj.findAll('h1')[0].text.strip())\n",
    "            title.append(bsobj.findAll('h1')[0].text.strip())\n",
    "            for i in bsobj.findAll('section', {'id': 'postingbody'}):\n",
    "                print(i.text.strip())\n",
    "\n",
    "print(\"*********choice menu**********\")\n",
    "print(\"Enter 1 for getting technology related updates\")\n",
    "print(\"Enter 2 for getting job related updates\")\n",
    "pref='y'\n",
    "while(pref=='y'):\n",
    "    choice = int(input(\"Enter your choice:\"))\n",
    "    if choice==1:\n",
    "         print(logo1)\n",
    "        hackernews()\n",
    "    elif choice==2:\n",
    "        print(logo2)\n",
    "        jobscrape()\n",
    "    else:\n",
    "        print(\"Invalid Choice\")\n",
    "    print(\"Do you want to continue?type y for yes and n for no\")\n",
    "    pref=input()\n",
    "print(\"******Hope you got the required information.Thank you for using this web scraper.*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e931cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
